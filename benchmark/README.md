# Metro Benchmark Project

This is a large-scale benchmark project for testing Metro's performance. It contains a configurable number of modules
(default: 500) organized in a realistic architecture with extensive use of `@ContributesBinding` and `@ContributesMultibinding` annotations.

## Architecture

The project is organized into three layers:

- **Core layer** (~16% of total): Fundamental utilities, data models, networking, platform abstractions
- **Features layer** (~70% of total): Business logic features like auth, user management, content, social, commerce,
  analytics
- **App layer** (~14% of total): UI components, navigation, integration glue, and dependency wiring

## Module Structure

Each module contributes 1-10 bindings using:

- `@ContributesBinding` for interface implementations
- `@ContributesMultibinding` for plugin-style extensions and initializers
- Realistic inter-module dependencies following the layered architecture
- 5 subcomponents for hierarchical scoping

## Generation

The entire project is generated by the `generate-projects.main.kts` script, which can be re-run to regenerate modules
with different parameters. This makes it easy to experiment with different scales and configurations.

The script supports multiple modes and configurable module counts:
- **Metro mode** (`--mode metro`): Uses Metro for dependency injection with metro interop
- **Anvil mode** (`--mode anvil`): Uses pure Anvil-KSP for dependency injection
- **Kotlin-inject + Anvil mode** (`--mode kotlin-inject-anvil`): Uses Metro with kotlin-inject + anvil interop
- **Module count** (`--count <number>`): Total number of modules to generate (default: 500)
- **Processor** (`--processor ksp|kapt`): Annotation processor for Anvil mode (default: ksp)

## Usage

```bash
# Generate the project for Metro mode with default 500 modules
kotlin generate-projects.main.kts --mode metro

# Generate the project for Anvil mode with default 500 modules
kotlin generate-projects.main.kts --mode anvil

# Generate a larger project with 1000 modules
kotlin generate-projects.main.kts --mode metro --count 1000

# Generate a smaller project for quick testing
kotlin generate-projects.main.kts --mode anvil --count 100

# Generate a project using kapt for dagger-compiler (Anvil mode)
kotlin generate-projects.main.kts --mode anvil --processor kapt

# Generate kotlin-inject + anvil mode project (uses Amazon kotlin-inject-anvil)
kotlin generate-projects.main.kts --mode kotlin-inject-anvil

# Build the entire benchmark
./gradlew build

# Run the app component (creates the full dependency graph)
./gradlew :app:component:run
```

## Benchmark Runner

Use the `run_benchmarks.sh` script for comprehensive performance testing:

```bash
# Run all benchmark modes (metro, anvil-ksp, anvil-kapt, kotlin-inject-anvil)
./run_benchmarks.sh all

# Run specific modes
./run_benchmarks.sh metro 500
./run_benchmarks.sh anvil-ksp 250
./run_benchmarks.sh anvil-kapt 750
./run_benchmarks.sh kotlin-inject-anvil 500

# Include clean build scenarios (opt-in)
./run_benchmarks.sh all --include-clean-builds
./run_benchmarks.sh metro 250 --include-clean-builds

# Build-only mode (skip gradle-profiler benchmarks)
./run_benchmarks.sh all --build-only

# Results are saved to timestamped directories in benchmark-results/
# Merged comparison HTMLs are generated for each test type (ABI, non-ABI, raw compilation, clean build)
# Uses bash + jq for fast HTML result merging
```

### Benchmark Scenarios

The benchmark suite includes several types of performance tests for each mode:

**Standard Scenarios (always included):**
- **ABI Change**: Measures incremental compilation when public API changes
- **Non-ABI Change**: Measures incremental compilation when implementation changes  
- **Raw Compilation**: Measures compilation performance of the (`:app:component`) module specifically with `--rerun-tasks`. This benchmarks raw contribution merging + graph/component generation + validation.

**Clean Build Scenarios (opt-in with `--include-clean-builds`):**
- **Clean Build**: Measures full compilation from scratch with no caches
  - Uses `cleanup-tasks = ["clean"]` to run clean before each iteration
  - Uses `clear-build-cache-before = BUILD` to clear Gradle build cache
  - Lower iteration count (3) and warm-ups (2) due to longer execution time

Clean build scenarios are useful for:
- Measuring cold build performance 
- Testing CI/ephemeral build scenarios
- Comparing full compilation times across different DI frameworks

## Modes

### Metro Mode
- Uses `dev.zacsweers.metro` plugin
- Uses `dev.zacsweers.anvil:annotations` with Metro interop
- Supports `AppScope` and `@SingleIn` scoping
- Generates `createGraph<AppComponent>()` for runtime execution

### Anvil Mode
- Uses `dev.zacsweers.anvil:compiler` with KSP or KAPT
- Uses `dagger.runtime` for dependency injection
- Uses standard `com.squareup.anvil.annotations` (via anvil-ksp fork)
- Uses `@Singleton` and `Unit::class` scope
- Generates Dagger components with `DaggerAppComponent.factory().create()`

### Kotlin-inject + Anvil Mode
- Uses `me.tatarka.inject:kotlin-inject-runtime` and `kotlin-inject-compiler-ksp` for dependency injection
- Uses `software.amazon.lastmile.kotlin.inject.anvil` compiler and runtime for code generation
- Uses `@SingleIn(AppScope::class)` scoping and `@ContributesMultibinding` for multibindings
- Uses `me.tatarka.inject.annotations.Inject` for dependency injection
- Uses abstract class with `@Component` and `@MergeComponent` pattern with `AppComponent::class.create()`

## Interop

The benchmark uses:

- `javax.inject` annotations for dependency injection
- `dev.zacsweers.anvil:annotations` (anvil-ksp fork) for contribution annotations
- Metro's interop system to bridge Anvil annotations to Metro's code generation

This tests Metro's ability to work with existing Anvil codebases and validates the interop functionality at scale.

## Statistics

- **Configurable module count** (default: 500, can scale from 100 to 1000+)
- **~5.5 contributions per module** (varies due to randomization, 1-10 range)
- **Proportional subcomponents** (~10% of app layer modules)
- **Realistic dependency graph** following architectural best practices

The benchmark scales proportionally with the module count:
- 100 modules: ~500 contributions, 1 subcomponent
- 500 modules: ~2,750 contributions, 7 subcomponents
- 1000 modules: ~5,400 contributions, 14 subcomponents

This provides comprehensive testing of Metro's compilation performance, memory usage, and incremental
compilation behavior across different project scales.
